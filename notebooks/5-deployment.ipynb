{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6949f8979a4b8ebdf3cf9a8317f987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93af093ec10c408d98dc536c4b363ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bce1991caa4e3baedeb7aa34f0208b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78994e63231f43e0ae528c8e860400c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kangelamw/negative-reviews-into-actionable-insights/commit/c1139493c5e3fc7c2da10c1e688a75fcff04bf65', commit_message='Upload folder using huggingface_hub', commit_description='', oid='c1139493c5e3fc7c2da10c1e688a75fcff04bf65', pr_url=None, repo_url=RepoUrl('https://huggingface.co/kangelamw/negative-reviews-into-actionable-insights', endpoint='https://huggingface.co', repo_type='model', repo_id='kangelamw/negative-reviews-into-actionable-insights'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the API\n",
    "api = HfApi()\n",
    "\n",
    "# Replace with your Hugging Face username\n",
    "username = \"kangelamw\" \n",
    "\n",
    "# Repo name\n",
    "repo_name = \"negative-reviews-into-actionable-insights\"\n",
    "repo_id = f\"{username}/{repo_name}\"\n",
    "\n",
    "# Path to model directory\n",
    "model_path = '../models/phi-2_full_2' \n",
    "\n",
    "# Create repo and upload\n",
    "api.create_repo(repo_id, exist_ok=True)\n",
    "api.upload_folder(\n",
    "    folder_path=model_path,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model card with required tags updated successfully\n",
      "Your model should now be deployable on the Inference API\n"
     ]
    }
   ],
   "source": [
    "# It needs a few more things\n",
    "from huggingface_hub import ModelCard, ModelCardData\n",
    "\n",
    "# Add model tags to the repository -- for searchability\n",
    "card_data = ModelCardData(\n",
    "    language=\"en\",\n",
    "    license=\"mit\",\n",
    "    library_name=\"peft\",\n",
    "    base_model=\"microsoft/phi-2\",\n",
    "    tags=[\"text-generation\", \"peft\", \"lora\", \"review-analysis\", \"business-intelligence\"]\n",
    ")\n",
    "\n",
    "# Create and push model card\n",
    "try:\n",
    "    card = ModelCard.from_template(\n",
    "        card_data,\n",
    "        model_id=repo_id,\n",
    "        ignore_metadata_errors=True  # Preserve existing README content\n",
    "    )\n",
    "    card.push_to_hub(repo_id)\n",
    "    print(\"Model card with required tags updated successfully\")\n",
    "    print(\"Your model should now be deployable on the Inference API\")\n",
    "except Exception as e:\n",
    "    print(f\"Error updating model card: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Repository contains 13 files.\n",
      "Files: ['.gitattributes', 'README.md', 'added_tokens.json', 'config.json', 'generation_config.json', 'merges.txt', 'model-00001-of-00002.safetensors', 'model-00002-of-00002.safetensors', 'model.safetensors.index.json', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'vocab.json']...\n",
      "View model at: https://huggingface.co/kangelamw/negative-reviews-into-actionable-insights\n"
     ]
    }
   ],
   "source": [
    "# Quick check if model was pushed successfully\n",
    "try:\n",
    "    # List a few files in the repository\n",
    "    files = api.list_repo_files(repo_id)\n",
    "    print(f\"Success! Repository contains {len(files)} files.\")\n",
    "    print(f\"Files: {files}...\")\n",
    "    print(f\"View model at: https://huggingface.co/{repo_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: The model is not ready for prod.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would want to use the model as an API for a web app, and preferably in Azure. I have the following options:\n",
    "\n",
    "- **Azure Machine Learning (Azure ML):** Best for managed inference and scalability.\n",
    "- **Azure Functions / Azure App Service:** For deploying a FastAPI-based API.\n",
    "\n",
    "#### **Model Hosting Choices**\n",
    "I can directly load the model using `transformers` from Hugging Face, but I also have the option to deploy it using **[Hugging Face's Inference API](https://endpoints.huggingface.co/)**:\n",
    "\n",
    "- **Self-Managed on Azure**  \n",
    "  - Deploy a **FastAPI** or **Flask** server hosting the model.\n",
    "  - Use **GPU-powered VM** for efficient inference.\n",
    "\n",
    "- **Hugging Face Inference API**  \n",
    "  - A fully managed solution for serving models.  \n",
    "  - I found this guide: [Hugging Face Inference Providers](https://huggingface.co/blog/inference-providers).\n",
    "\n",
    "#### **Deployment Process on Azure**\n",
    "To deploy the model efficiently:\n",
    "\n",
    "1. **Containerize the Model API using Docker**  \n",
    "   - Write a `Dockerfile` to package the model and API.\n",
    "\n",
    "2. **Push to Azure Container Registry (ACR)**  \n",
    "   - Store the container image in **Azure ACR** for deployment.\n",
    "\n",
    "#### **Deploy the API on Azure**\n",
    "   - Use **Azure App Service** (simpler for REST API hosting).  \n",
    "   - Or deploy on **Azure Kubernetes Service (AKS)** for scalable inference.\n",
    "\n",
    "This setup will allow my **fine-tuned Phi-2 model** to serve as an API for a web app, ensuring **scalability, efficiency, and cost-effectiveness** on Azure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
